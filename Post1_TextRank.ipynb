{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Rank Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper Name:** TextRank: Bringing Order into Texts\n",
    "\n",
    "**Paper Link:** http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text rank algorithm is a graph based ranking algorithm that draws it's basic concept from the page rank algorithm developed by Larry Page and Sergey Brinn at Google and applies the page rank methodology for ranking webpages to rank sentences in NLP. In this notebook we explore the TextRank paper published by **Rada Mihalcea** and **Paul Tarau**. This is the **#Post1** of the **#ML_Reading_101_Challenge**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Rank Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page rank model given by Page and Brinn ranks the pages on the basis of following formulae:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://aryancodify.tech/wp-content/uploads/2018/07/pageRank.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Vi is the ith vertex, d is the damping factor whose value is between 0 and 1, In(Vi) are the set of vertices which point to Vi and Out(Vi) are the set of vertices that Vi points to. d is normally set to around 0.85 in Page rank algortihm and same is being kept for th etext rank algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically this algorithm takes into consideration vote or recommendation of previous vertices to score or rank the next vertices in the graph. The more the rank of previous vertices poiting to the current vertex better the rank of current vertex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is run for multiple iterations until the rank S'(Vi) - S(Vi) > epsilon between two iterations. Once the difference in rank between multiple iterations drops below epsilon the algorithm is said to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Graphs In Text Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs in text rank algorithm  are weighted graphs becuase in text extracted from natural language there might be partial or multiple links between vertices. The strength of connection between two vertices Vi and Vj is represented by wij. Thus the modified formula for Text rank becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://aryancodify.tech/wp-content/uploads/2018/07/textRank.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Text as Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next major task is to identify text entities to be represented as the vertices and the edges connecting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Rank For Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper demonstrates how the graph based Text rank algoritm trumps the classic Supervised Heuristic methods for keyword extraction.\n",
    "\n",
    "**Vertices:** Sequences of one or more lexical units extracted from text.\n",
    "\n",
    "**Edges:** Co-occurrence relation i.e. two vertices are connected if their corresponding lexical units co-occur within a window of maximum words, where can be set anywhere from 2 to 10 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vertices added to the graph can be restricted with syntactic filters, which select only lexical units of a certain part of speech like nouns, verbs etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> After the graph is constructed the Text rank algorithm is run on the graph till convergence to find the rank of lexical units and they are arranged in decreasing order of their score to determine rank. \n",
    "\n",
    "-> At a post processing stage the words that occur adjacent to each other are collapsed to multi-word keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Rank** despite being unsupervised achieves highest precision and F1 score. The best score was obtained where syntactic filter allowed **nouns** and **adjectives** only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Rank For Sentence Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vertices:** Bag Of Words kind of model with count of occurence of each word as an element of the vector.\n",
    "\n",
    "**Edges:** Similarity between two sentences represented as number of common tokens between lexical representations of two sentences.\n",
    "\n",
    "Given two sentences **Si** and **Sj** with a sentence having **Ni** words appearing in the sentence Si as w1(i), w2(i)--Wni(i). The **similarity** score can be given as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://aryancodify.tech/wp-content/uploads/2018/07/simi.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other metrics like cosine score and longest common subsequence are also possible but not discussed in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the graph is constructed the ranking algorithm is run to identify the top N sentences on basis of their score and they form the extractive summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TextRank works well because it does notonly rely on the local context of a text unit (vertex), but rather it takes into account information recursively drawn from the entire text (graph).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus TextRank succeeds as an unsupervised method for keyword and sentence extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary example using Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"In this paper, we introduced TextRank – a graph based ranking model for text processing, and show how it can be successfully used for natural language applications. In particular, we proposed and evaluated two innovative unsupervised approaches for keyword and sentence extraction, and showed that the accuracy achieved by TextRank in these applications is competitive with that of previously proposed state-of-the-art algorithms. An important aspect of TextRank is that it does not require deep linguistic knowledge, nor domain or language specific annotated corpora, which makes it highly portable to other domains, genres, or language.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this paper, we introduced TextRank – a graph based ranking model for text processing, and show how it can be successfully used for natural language applications.\n"
     ]
    }
   ],
   "source": [
    "print(summarize(txt,ratio=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
